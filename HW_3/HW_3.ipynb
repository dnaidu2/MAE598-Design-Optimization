{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f39c9923",
   "metadata": {},
   "source": [
    "# Problem 1\n",
    "## Formulate the Least Square Problem for Vapor-liquid equilibria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a1e3ffb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im1 = Image.open(r'C:\\Users\\divya\\PycharmProjects\\MAE598-Design-Optimization\\HW_3\\P1_question.png')\n",
    "rgb_im = im1.convert('RGB')\n",
    "rgb_im.save(r'C:\\Users\\divya\\PycharmProjects\\MAE598-Design-Optimization\\HW_3\\P1.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930d1e5c",
   "metadata": {},
   "source": [
    "<img src = \"P1.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2f960bcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vapor-liquid equilibria model: tensor([28.8241, 34.6443, 36.4530, 36.8673, 36.8740, 36.7498, 36.3904, 35.3848,\n",
      "        32.9478, 27.7300, 17.4732], dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "A12 and A21 values: [1.9584184 1.6891861]\n",
      "Loss: 0.000716000944521511\n",
      "Difference: tensor(0.7241, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(0.2443, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(-0.2470, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(-0.0327, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(0.0740, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(0.0498, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(-0.1096, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(-0.0152, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(0.0478, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(0.0300, dtype=torch.float64, grad_fn=<SubBackward0>)\n",
      "Difference: tensor(-0.0268, dtype=torch.float64, grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch as t\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Given data for a(1,2,3) for water(H2o) and 1,4 dioxane system(14_ds)\n",
    "\n",
    "T = 20\n",
    "a_H2o = t.tensor([8.07131, 1730.63, 233.426])\n",
    "a_14_ds = t.tensor([7.43155, 1554.679, 240.337])\n",
    "\n",
    "# Calculation of the saturation pressures by using Antoine equation\n",
    "\n",
    "psat_H2o   = 10**(a_H2o[0]-(a_H2o[1]/(T+a_H2o[2])))\n",
    "psat_14_ds = 10**(a_14_ds[0]-(a_14_ds[1]/(T+a_14_ds[2])))\n",
    "psat       = t.tensor([psat_H2o,psat_14_ds],requires_grad=False, dtype =t.float64)\n",
    "\n",
    "\n",
    "# Given measured data for x1,x2 and p\n",
    "x1 = np.asarray(np.arange(0.0,1.1,0.1))\n",
    "x2 = 1-np.asarray(x1)\n",
    "x  = t.tensor([x1,x2], requires_grad=False, dtype =t.float64)\n",
    "p  = np.asarray([28.1, 34.4, 36.7, 36.9, 36.8, 36.7, 36.5, 35.4, 32.9, 27.7, 17.5])\n",
    "\n",
    "# Defining initial values for variables A1 and A2\n",
    "A = Variable(t.tensor([1.0,1.0]),requires_grad=True)\n",
    "\n",
    "# Definig model for vapor - liquid equilibria data\n",
    "def model(x,A,psat):\n",
    "    t_A12 = (A[0]*(A[1]*x[1]/(A[0]*x[0]+A[1]*x[1]))**2)\n",
    "    t_A21 = (A[1]*(A[0]*x[0]/(A[0]*x[0]+A[1]*x[1]))**2)\n",
    "    term1 = x[0]*t.exp(t_A12)*psat[0]\n",
    "    term2 = x[1]*t.exp(t_A21)*psat[1]\n",
    "    return term1+term2\n",
    "\n",
    "# Fix the step size\n",
    "a = 0.001\n",
    "\n",
    "# calculating gradient\n",
    "for i in range(1000):  # TODO: change the termination criterion\n",
    "    for i in range(0,len(x1)):\n",
    "        loss = (model(x,A,psat)[i]-p[i])**2\n",
    "        loss.backward()\n",
    "    A.grad.numpy()\n",
    "      \n",
    "# no_grad() specifies that the operations within this context are not part of the computational graph, i.e., we don't need the gradient descent algorithm itself to be differentiable with respect to x\n",
    "    with t.no_grad():\n",
    "        A -= (a * A.grad).requires_grad_(True)\n",
    "        \n",
    "        # need to clear the gradient at every step, or otherwise it will accumulate...\n",
    "        A.grad.zero_()\n",
    "        \n",
    "print(\"Vapor-liquid equilibria model:\",model(x,A,psat))\n",
    "print(\"A12 and A21 values:\",A.data.numpy())\n",
    "print(\"Loss:\",loss.data.numpy())\n",
    "\n",
    "# Compare your optimized model with the data\n",
    "for n in range(0,len(p)):\n",
    "    diff = model(x,A,psat)[n]-p[n]\n",
    "    print(\"Difference:\",diff)\n",
    "\n",
    "# Graph\n",
    "fig, c = plt.subplots()\n",
    "  \n",
    "c.scatter(x1, p, c ='b', label ='Actual data')\n",
    "c.plot(x1, model(x,A,psat).detach().numpy(), c ='r', label ='Optimized model')\n",
    "plt.scatter(x2, p,c ='r',label ='x2_Actual data')\n",
    "plt.plot(x2, model(x,A,psat).detach().numpy(),label ='x2_Optimized model')\n",
    "plt.legend()\n",
    "plt.title('Vapor Liquid equilibria data Vs OLS model')\n",
    "leg = c.legend(loc =\"lower center\")\n",
    "plt.show()\n",
    "             "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29f283f",
   "metadata": {},
   "source": [
    "#### Does your model fit well with the data?\n",
    "From the above graph, we can see that the P values for all (x1,x2) is almost same for given Vapor Liquid equilibria data and OLS optimized model. The loss and difference between 2 P's is also small.\n",
    "And the optimized model curve and actual data curve is neither underfitting nor overfitting and paases through all the points in given data.\n",
    "So, the designed optimized OLS model fits well with the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548611b",
   "metadata": {},
   "source": [
    "# Problem 2\n",
    "## Bayesian Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b063966b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "im1 = Image.open(r'C:\\Users\\divya\\PycharmProjects\\MAE598-Design-Optimization\\HW_3\\P2_q.png')\n",
    "rgb_im = im1.convert('RGB')\n",
    "rgb_im.save(r'C:\\Users\\divya\\PycharmProjects\\MAE598-Design-Optimization\\HW_3\\P2.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b36927",
   "metadata": {},
   "source": [
    "<img src = \"P2.jpg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "84ae9b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    x1     |    x2     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m-0.4979  \u001b[0m | \u001b[0m 0.8813  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-110.1   \u001b[0m | \u001b[0m-2.999   \u001b[0m | \u001b[0m-0.7907  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4933  \u001b[0m | \u001b[0m-0.3849  \u001b[0m | \u001b[0m 1.039   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2833  \u001b[0m | \u001b[0m 1.599   \u001b[0m | \u001b[0m-0.5696  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-162.9   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-47.77   \u001b[0m | \u001b[0m 0.3665  \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-150.9   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7638  \u001b[0m | \u001b[0m 0.4683  \u001b[0m | \u001b[0m-0.02769 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-48.27   \u001b[0m | \u001b[0m-2.043   \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.236   \u001b[0m | \u001b[0m 1.314   \u001b[0m | \u001b[0m 0.6422  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-50.26   \u001b[0m | \u001b[0m 0.5766  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-52.97   \u001b[0m | \u001b[0m-1.299   \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.06    \u001b[0m | \u001b[0m-0.7025  \u001b[0m | \u001b[0m-0.5363  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-7.993   \u001b[0m | \u001b[0m 2.197   \u001b[0m | \u001b[0m 0.07143 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-48.19   \u001b[0m | \u001b[0m-0.8016  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.426   \u001b[0m | \u001b[0m-1.507   \u001b[0m | \u001b[0m 0.2863  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-107.6   \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m 1.181   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.305   \u001b[0m | \u001b[0m 1.361   \u001b[0m | \u001b[0m-0.01255 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.03572 \u001b[0m | \u001b[0m 0.4022  \u001b[0m | \u001b[0m 0.7855  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m 0.5131  \u001b[0m | \u001b[0m-0.8858  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.746   \u001b[0m | \u001b[0m-0.8282  \u001b[0m | \u001b[0m 0.09644 \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.8247  \u001b[0m | \u001b[0m-1.335   \u001b[0m | \u001b[0m 0.9693  \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 0.9014  \u001b[0m | \u001b[95m-0.0734  \u001b[0m | \u001b[95m-0.6431  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.6251  \u001b[0m | \u001b[0m 1.033   \u001b[0m | \u001b[0m-0.6554  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.03    \u001b[0m | \u001b[0m-0.3903  \u001b[0m | \u001b[0m-1.169   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.223   \u001b[0m | \u001b[0m-1.358   \u001b[0m | \u001b[0m-0.5658  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.7812  \u001b[0m | \u001b[0m-1.108   \u001b[0m | \u001b[0m 0.5979  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m-0.05554 \u001b[0m | \u001b[0m 0.4046  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-1.608   \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.4655  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.496   \u001b[0m | \u001b[0m-1.242   \u001b[0m | \u001b[0m-0.1562  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-3.177   \u001b[0m | \u001b[0m-0.9934  \u001b[0m | \u001b[0m-0.9956  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.2506  \u001b[0m | \u001b[0m 0.4613  \u001b[0m | \u001b[0m-0.512   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-1.837   \u001b[0m | \u001b[0m 1.823   \u001b[0m | \u001b[0m-0.1931  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m-0.08294 \u001b[0m | \u001b[0m 0.8368  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.03018 \u001b[0m | \u001b[0m-0.1394  \u001b[0m | \u001b[0m-0.1282  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-1.517   \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m-1.049   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.383   \u001b[0m | \u001b[0m 1.78    \u001b[0m | \u001b[0m 0.3605  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.05351 \u001b[0m | \u001b[0m-1.581   \u001b[0m | \u001b[0m 0.7205  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.3066  \u001b[0m | \u001b[0m 0.086   \u001b[0m | \u001b[0m-0.9655  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 0.3051  \u001b[0m | \u001b[0m 0.4538  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.03219 \u001b[0m | \u001b[0m-0.3843  \u001b[0m | \u001b[0m-0.8382  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.04223 \u001b[0m | \u001b[0m-0.4333  \u001b[0m | \u001b[0m 0.4041  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.2273  \u001b[0m | \u001b[0m 0.164   \u001b[0m | \u001b[0m-0.2792  \u001b[0m |\n",
      "| \u001b[95m 44      \u001b[0m | \u001b[95m 0.9568  \u001b[0m | \u001b[95m 0.2315  \u001b[0m | \u001b[95m-0.7249  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.4103  \u001b[0m | \u001b[0m-1.398   \u001b[0m | \u001b[0m 0.6456  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.3414  \u001b[0m | \u001b[0m 1.342   \u001b[0m | \u001b[0m-0.7697  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.063   \u001b[0m | \u001b[0m 0.9107  \u001b[0m | \u001b[0m-0.9869  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-1.941   \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 0.8889  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.8011  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 1.062   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.6696  \u001b[0m | \u001b[0m-0.848   \u001b[0m | \u001b[0m 0.9324  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.01326 \u001b[0m | \u001b[0m 0.1221  \u001b[0m | \u001b[0m 0.1245  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-1.998   \u001b[0m | \u001b[0m-1.045   \u001b[0m | \u001b[0m-0.6288  \u001b[0m |\n",
      "=================================================\n",
      "{'target': 0.9568135408880579, 'params': {'x1': 0.23151603129184473, 'x2': -0.7248785139747396}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def fun(x1,x2):\n",
    "    return -((4-(2.1*x1**2)+((x1**4)/3))*x1**2+(x1*x2)+(-4+(4*x2**2))*x2**2)\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'x1': (-3, 3), 'x2': (-2, 2)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=fun,pbounds=pbounds,random_state=1)\n",
    "optimizer.maximize(init_points=2,n_iter=50)\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ff9ea6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    x1     |    x2     |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.265   \u001b[0m | \u001b[0m-0.4979  \u001b[0m | \u001b[0m 0.8813  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-110.1   \u001b[0m | \u001b[0m-2.999   \u001b[0m | \u001b[0m-0.7907  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4933  \u001b[0m | \u001b[0m-0.3849  \u001b[0m | \u001b[0m 1.039   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.2833  \u001b[0m | \u001b[0m 1.599   \u001b[0m | \u001b[0m-0.5696  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-162.9   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-47.77   \u001b[0m | \u001b[0m 0.3665  \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-150.9   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.7638  \u001b[0m | \u001b[0m 0.4683  \u001b[0m | \u001b[0m-0.02769 \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-48.27   \u001b[0m | \u001b[0m-2.043   \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-2.236   \u001b[0m | \u001b[0m 1.314   \u001b[0m | \u001b[0m 0.6422  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-50.26   \u001b[0m | \u001b[0m 0.5766  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-52.97   \u001b[0m | \u001b[0m-1.299   \u001b[0m | \u001b[0m-2.0     \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-1.06    \u001b[0m | \u001b[0m-0.7025  \u001b[0m | \u001b[0m-0.5363  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-7.993   \u001b[0m | \u001b[0m 2.197   \u001b[0m | \u001b[0m 0.07143 \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-48.19   \u001b[0m | \u001b[0m-0.8016  \u001b[0m | \u001b[0m 2.0     \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-1.426   \u001b[0m | \u001b[0m-1.507   \u001b[0m | \u001b[0m 0.2863  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-107.6   \u001b[0m | \u001b[0m-3.0     \u001b[0m | \u001b[0m 1.181   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-2.305   \u001b[0m | \u001b[0m 1.361   \u001b[0m | \u001b[0m-0.01255 \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.03572 \u001b[0m | \u001b[0m 0.4022  \u001b[0m | \u001b[0m 0.7855  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.217   \u001b[0m | \u001b[0m 0.5131  \u001b[0m | \u001b[0m-0.8858  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m-1.746   \u001b[0m | \u001b[0m-0.8282  \u001b[0m | \u001b[0m 0.09644 \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.8247  \u001b[0m | \u001b[0m-1.335   \u001b[0m | \u001b[0m 0.9693  \u001b[0m |\n",
      "| \u001b[95m 23      \u001b[0m | \u001b[95m 0.9014  \u001b[0m | \u001b[95m-0.0734  \u001b[0m | \u001b[95m-0.6431  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.6251  \u001b[0m | \u001b[0m 1.033   \u001b[0m | \u001b[0m-0.6554  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-3.03    \u001b[0m | \u001b[0m-0.3903  \u001b[0m | \u001b[0m-1.169   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-2.223   \u001b[0m | \u001b[0m-1.358   \u001b[0m | \u001b[0m-0.5658  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.7812  \u001b[0m | \u001b[0m-1.108   \u001b[0m | \u001b[0m 0.5979  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.5577  \u001b[0m | \u001b[0m-0.05554 \u001b[0m | \u001b[0m 0.4046  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-1.608   \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 0.4655  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-2.496   \u001b[0m | \u001b[0m-1.242   \u001b[0m | \u001b[0m-0.1562  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m-3.177   \u001b[0m | \u001b[0m-0.9934  \u001b[0m | \u001b[0m-0.9956  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.2506  \u001b[0m | \u001b[0m 0.4613  \u001b[0m | \u001b[0m-0.512   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m-1.837   \u001b[0m | \u001b[0m 1.823   \u001b[0m | \u001b[0m-0.1931  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.8815  \u001b[0m | \u001b[0m-0.08294 \u001b[0m | \u001b[0m 0.8368  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m-0.03018 \u001b[0m | \u001b[0m-0.1394  \u001b[0m | \u001b[0m-0.1282  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m-1.517   \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m-1.049   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m-2.383   \u001b[0m | \u001b[0m 1.78    \u001b[0m | \u001b[0m 0.3605  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.05351 \u001b[0m | \u001b[0m-1.581   \u001b[0m | \u001b[0m 0.7205  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.3066  \u001b[0m | \u001b[0m 0.086   \u001b[0m | \u001b[0m-0.9655  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.1613  \u001b[0m | \u001b[0m 0.3051  \u001b[0m | \u001b[0m 0.4538  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m-0.03219 \u001b[0m | \u001b[0m-0.3843  \u001b[0m | \u001b[0m-0.8382  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.04223 \u001b[0m | \u001b[0m-0.4333  \u001b[0m | \u001b[0m 0.4041  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.2273  \u001b[0m | \u001b[0m 0.164   \u001b[0m | \u001b[0m-0.2792  \u001b[0m |\n",
      "| \u001b[95m 44      \u001b[0m | \u001b[95m 0.9568  \u001b[0m | \u001b[95m 0.2315  \u001b[0m | \u001b[95m-0.7249  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m-0.4103  \u001b[0m | \u001b[0m-1.398   \u001b[0m | \u001b[0m 0.6456  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m-0.3414  \u001b[0m | \u001b[0m 1.342   \u001b[0m | \u001b[0m-0.7697  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m-1.063   \u001b[0m | \u001b[0m 0.9107  \u001b[0m | \u001b[0m-0.9869  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m-1.941   \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 0.8889  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m-0.8011  \u001b[0m | \u001b[0m 0.1395  \u001b[0m | \u001b[0m 1.062   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m-0.6696  \u001b[0m | \u001b[0m-0.848   \u001b[0m | \u001b[0m 0.9324  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m-0.01326 \u001b[0m | \u001b[0m 0.1221  \u001b[0m | \u001b[0m 0.1245  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m-1.998   \u001b[0m | \u001b[0m-1.045   \u001b[0m | \u001b[0m-0.6288  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.1982  \u001b[0m | \u001b[0m-0.2935  \u001b[0m | \u001b[0m-0.4573  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.8548  \u001b[0m | \u001b[0m 0.1206  \u001b[0m | \u001b[0m 0.6809  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.9391  \u001b[0m | \u001b[0m-0.2347  \u001b[0m | \u001b[0m 0.6788  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m-0.1307  \u001b[0m | \u001b[0m-0.707   \u001b[0m | \u001b[0m 0.6204  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.2154  \u001b[0m | \u001b[0m 1.704   \u001b[0m | \u001b[0m-0.7984  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m-1.172   \u001b[0m | \u001b[0m 1.952   \u001b[0m | \u001b[0m-0.5798  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m-2.317   \u001b[0m | \u001b[0m 1.456   \u001b[0m | \u001b[0m 0.3191  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.729   \u001b[0m | \u001b[0m-0.08331 \u001b[0m | \u001b[0m-0.8415  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m-1.456   \u001b[0m | \u001b[0m 0.8525  \u001b[0m | \u001b[0m-0.2585  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.01197 \u001b[0m | \u001b[0m 0.6963  \u001b[0m | \u001b[0m-0.7121  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.846   \u001b[0m | \u001b[0m 0.09967 \u001b[0m | \u001b[0m-0.5429  \u001b[0m |\n",
      "| \u001b[95m 64      \u001b[0m | \u001b[95m 1.009   \u001b[0m | \u001b[95m 0.08717 \u001b[0m | \u001b[95m-0.7634  \u001b[0m |\n",
      "| \u001b[95m 65      \u001b[0m | \u001b[95m 1.016   \u001b[0m | \u001b[95m-0.0768  \u001b[0m | \u001b[95m 0.6684  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m-0.6973  \u001b[0m | \u001b[0m-0.4357  \u001b[0m | \u001b[0m-0.04482 \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7402  \u001b[0m | \u001b[0m-0.2604  \u001b[0m | \u001b[0m 0.8575  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7716  \u001b[0m | \u001b[0m 0.09088 \u001b[0m | \u001b[0m 0.8209  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7494  \u001b[0m | \u001b[0m 0.2638  \u001b[0m | \u001b[0m-0.853   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.592   \u001b[0m | \u001b[0m-0.05509 \u001b[0m | \u001b[0m-0.4419  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m-0.1982  \u001b[0m | \u001b[0m 0.5388  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.8918  \u001b[0m | \u001b[0m 0.02101 \u001b[0m | \u001b[0m 0.5888  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.6328  \u001b[0m | \u001b[0m 0.4332  \u001b[0m | \u001b[0m-0.7266  \u001b[0m |\n",
      "| \u001b[95m 74      \u001b[0m | \u001b[95m 1.028   \u001b[0m | \u001b[95m 0.06885 \u001b[0m | \u001b[95m-0.6943  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m-0.01896 \u001b[0m | \u001b[0m 0.7198  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m-0.1365  \u001b[0m | \u001b[0m 0.727   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 0.1508  \u001b[0m | \u001b[0m-0.6719  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.9952  \u001b[0m | \u001b[0m-0.002102\u001b[0m | \u001b[0m-0.7269  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.673   \u001b[0m | \u001b[0m-0.4029  \u001b[0m | \u001b[0m 0.68    \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.83    \u001b[0m | \u001b[0m 0.269   \u001b[0m | \u001b[0m-0.6166  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m 0.1301  \u001b[0m | \u001b[0m-0.7634  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 0.04784 \u001b[0m | \u001b[0m-0.6528  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 1.024   \u001b[0m | \u001b[0m-0.0862  \u001b[0m | \u001b[0m 0.742   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 1.008   \u001b[0m | \u001b[0m-0.1174  \u001b[0m | \u001b[0m 0.6625  \u001b[0m |\n",
      "| \u001b[95m 85      \u001b[0m | \u001b[95m 1.028   \u001b[0m | \u001b[95m 0.09813 \u001b[0m | \u001b[95m-0.6934  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m-0.04281 \u001b[0m | \u001b[0m 0.6968  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m-0.1759  \u001b[0m | \u001b[0m 0.7383  \u001b[0m |\n",
      "| \u001b[95m 88      \u001b[0m | \u001b[95m 1.03    \u001b[0m | \u001b[95m-0.1024  \u001b[0m | \u001b[95m 0.7242  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 1.026   \u001b[0m | \u001b[0m 0.06226 \u001b[0m | \u001b[0m-0.7288  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 1.029   \u001b[0m | \u001b[0m 0.1089  \u001b[0m | \u001b[0m-0.7239  \u001b[0m |\n",
      "| \u001b[95m 91      \u001b[0m | \u001b[95m 1.031   \u001b[0m | \u001b[95m-0.09406 \u001b[0m | \u001b[95m 0.7221  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.9972  \u001b[0m | \u001b[0m 0.06599 \u001b[0m | \u001b[0m-0.7716  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 1.028   \u001b[0m | \u001b[0m-0.1186  \u001b[0m | \u001b[0m 0.7101  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m-0.03578 \u001b[0m | \u001b[0m 0.7431  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 1.012   \u001b[0m | \u001b[0m-0.05256 \u001b[0m | \u001b[0m 0.6675  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 0.1461  \u001b[0m | \u001b[0m-0.7303  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.1034  \u001b[0m | \u001b[0m-0.6774  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m 0.03673 \u001b[0m | \u001b[0m-0.7066  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 1.021   \u001b[0m | \u001b[0m-0.134   \u001b[0m | \u001b[0m 0.6953  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m-0.08841 \u001b[0m | \u001b[0m 0.7254  \u001b[0m |\n",
      "| \u001b[0m 101     \u001b[0m | \u001b[0m 1.03    \u001b[0m | \u001b[0m 0.09519 \u001b[0m | \u001b[0m-0.7277  \u001b[0m |\n",
      "| \u001b[0m 102     \u001b[0m | \u001b[0m 1.005   \u001b[0m | \u001b[0m-0.01364 \u001b[0m | \u001b[0m 0.6856  \u001b[0m |\n",
      "=================================================\n",
      "{'target': 1.03085414291499, 'params': {'x1': -0.09406448078584173, 'x2': 0.7221310983970208}}\n"
     ]
    }
   ],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "def fun(x1,x2):\n",
    "    return -((4-(2.1*x1**2)+((x1**4)/3))*x1**2+(x1*x2)+(-4+(4*x2**2))*x2**2)\n",
    "\n",
    "# Bounded region of parameter space\n",
    "pbounds = {'x1': (-3, 3), 'x2': (-2, 2)}\n",
    "\n",
    "optimizer = BayesianOptimization(f=fun,pbounds=pbounds,random_state=1)\n",
    "optimizer.maximize(init_points=2,n_iter=100)\n",
    "print(optimizer.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "93fe862e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0])]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=np.array([0,0])\n",
    "\n",
    "obj = lambda x: ((4-(2.1*x[0]**2)+((x[0]**4)/3))*x[0]**2+(x[0]*x[1])+(-4+(4*x[1]**2))*x[1]**2)\n",
    "def grad(x):\n",
    "    return np.array([8*x[0]-2.1*4*x[0]**3+2*x[0]**5+x[1], x[0]-8*x[1]+16*x[1]**3])\n",
    "\n",
    "eps = 1e-3  # termination criterion\n",
    "x0 = np.array([0,0])\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps\n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "a = 0.01  # set a fixed step size to start with\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x, d):\n",
    "    a = 0.01  # initialize step size\n",
    "    \n",
    "    def phi(a,x,d):\n",
    "        return obj(x)+a*0.8*np.dot(grad(x),d)\n",
    "\n",
    "    while phi(a,x,d)<obj(x+a*d):  # while phi(a,x)<obj(x-a*grad(x)): # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "        \n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    d = -grad(x)\n",
    "    \n",
    "    a = line_search(x, d)\n",
    "    \n",
    "    x = x+a*d\n",
    "    #difference = abs(soln-)\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "#     error\n",
    "soln  # print the search trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9d7f5ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Equation 1:\n",
      "Eq(2*x**5 - 8.4*x**3 + 8*x + y, 0)\n",
      "Equation 2\n",
      "Eq(x + 16*y**3 - 8*y, 0)\n",
      "[(0.0, 0.0)]\n"
     ]
    }
   ],
   "source": [
    "from sympy import symbols, Eq, solve\n",
    "\n",
    "x,y = symbols('x,y')\n",
    "eq1 = Eq((8*x-(2.1*4*x**3)+2*x**5+y), 0)\n",
    "print(\"Equation 1:\")\n",
    "print(eq1)\n",
    "eq2 = Eq((x-(8*y)+16*y**3), 0)\n",
    "print(\"Equation 2\")\n",
    "print(eq2)\n",
    "  \n",
    "print(solve((eq1, eq2), (x, y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7354dbdc",
   "metadata": {},
   "source": [
    "#### Gradiant Descent method with inital values from Bayesian optimization, iter = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "73c9342c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.95599524 -0.06293878]\n",
      "[ 0.8912279  -0.06170133]\n",
      "[ 0.83003087 -0.06005521]\n",
      "[ 0.77235494 -0.05810418]\n",
      "[ 0.71812001 -0.05593324]\n",
      "[ 0.66722229 -0.05361173]\n",
      "[ 0.61954046 -0.05119599]\n",
      "[ 0.57494084 -0.04873149]\n",
      "[ 0.53328167 -0.04625471]\n",
      "[ 0.49441658 -0.04379461]\n",
      "[ 0.45819743 -0.04137395]\n",
      "[ 0.42447654 -0.03901033]\n",
      "[ 0.39310842 -0.03671711]\n",
      "[ 0.3639511  -0.03450412]\n",
      "[ 0.33686711 -0.03237834]\n",
      "[ 0.31172423 -0.03034437]\n",
      "[ 0.28839594 -0.02840491]\n",
      "[ 0.2667617 -0.0265611]\n",
      "[ 0.24670717 -0.02481286]\n",
      "[ 0.22812419 -0.02315911]\n",
      "[ 0.21091077 -0.02159799]\n",
      "[ 0.19497093 -0.02012707]\n",
      "[ 0.1802146  -0.01874345]\n",
      "[ 0.16655735 -0.01744391]\n",
      "[ 0.15392021 -0.01622502]\n",
      "[ 0.14222938 -0.01508318]\n",
      "[ 0.13141601 -0.01401473]\n",
      "[ 0.12141592 -0.01301599]\n",
      "[ 0.11216936 -0.01208327]\n",
      "[ 0.10362072 -0.01121298]\n",
      "[ 0.09571832 -0.01040156]\n",
      "[ 0.08841413 -0.0096456 ]\n",
      "[ 0.08166358 -0.00894176]\n",
      "[ 0.07542527 -0.00828686]\n",
      "[ 0.06966084 -0.00767784]\n",
      "[ 0.0643347  -0.00711179]\n",
      "[ 0.05941388 -0.00658593]\n",
      "[ 0.05486783 -0.00609762]\n",
      "[ 0.05066825 -0.00564437]\n",
      "[ 0.04678895 -0.00522383]\n",
      "[ 0.04320569 -0.00483378]\n",
      "[ 0.03989601 -0.00447212]\n",
      "[ 0.03683917 -0.00413689]\n",
      "[ 0.03401594 -0.00382625]\n",
      "[ 0.03140857 -0.00353847]\n",
      "[ 0.02900063 -0.00327193]\n",
      "[ 0.02677694 -0.00302513]\n",
      "[ 0.02472344 -0.00279664]\n",
      "[ 0.02282716 -0.00258516]\n",
      "[ 0.02107611 -0.00238945]\n",
      "[ 0.01945919 -0.00220837]\n",
      "[ 0.01796615 -0.00204085]\n",
      "[ 0.01658754 -0.0018859 ]\n",
      "[ 0.01531459 -0.00174259]\n",
      "[ 0.01413924 -0.00161007]\n",
      "[ 0.013054   -0.00148754]\n",
      "[ 0.01205199 -0.00137426]\n",
      "[ 0.01112684 -0.00126954]\n",
      "[ 0.01027265 -0.00117274]\n",
      "[ 0.00948399 -0.00108327]\n",
      "[ 0.00875584 -0.00100059]\n",
      "[ 0.00808357 -0.00092419]\n",
      "[ 0.00746289 -0.00085358]\n",
      "[ 0.00688984 -0.00078835]\n",
      "[ 0.00636077 -0.00072808]\n",
      "[ 0.00587232 -0.00067239]\n",
      "[ 0.00542136 -0.00062095]\n",
      "[ 0.00500502 -0.00057343]\n",
      "[ 0.00462064 -0.00052953]\n",
      "[ 0.00426577 -0.00048899]\n",
      "[ 0.00393815 -0.00045154]\n",
      "[ 0.00363569 -0.00041695]\n",
      "[ 0.00335645 -0.000385  ]\n",
      "[ 0.00309865 -0.0003555 ]\n",
      "[ 0.00286065 -0.00032825]\n",
      "[ 0.00264093 -0.00030308]\n",
      "[ 0.00243808 -0.00027985]\n",
      "[ 0.00225081 -0.00025839]\n",
      "[ 0.00207792 -0.00023857]\n",
      "[ 0.00191831 -0.00022027]\n",
      "[ 0.00177096 -0.00020337]\n",
      "[ 0.00163492 -0.00018777]\n",
      "[ 0.00150934 -0.00017336]\n",
      "[ 0.0013934  -0.00016006]\n",
      "[ 0.00128636 -0.00014778]\n",
      "[ 0.00118755 -0.00013644]\n",
      "[ 0.00109632 -0.00012596]\n",
      "[ 0.00101211 -0.00011629]\n",
      "[ 0.00093436 -0.00010737]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.23151603, -0.72487851]),\n",
       " array([ 0.2212726, -0.7242421]),\n",
       " array([ 0.21171265, -0.72361271]),\n",
       " array([ 0.20280037, -0.7229957 ]),\n",
       " array([ 0.19450006, -0.72239515]),\n",
       " array([ 0.18677651, -0.72181411]),\n",
       " array([ 0.17959531, -0.72125477]),\n",
       " array([ 0.17292309, -0.72071866]),\n",
       " array([ 0.16672769, -0.7202067 ]),\n",
       " array([ 0.16097828, -0.71971938]),\n",
       " array([ 0.15564546, -0.71925683]),\n",
       " array([ 0.15070129, -0.71881889]),\n",
       " array([ 0.14611932, -0.71840515]),\n",
       " array([ 0.14187455, -0.71801505]),\n",
       " array([ 0.13794347, -0.71764787]),\n",
       " array([ 0.13430396, -0.71730283]),\n",
       " array([ 0.13093529, -0.71697905]),\n",
       " array([ 0.12781805, -0.71667561]),\n",
       " array([ 0.12493409, -0.71639156]),\n",
       " array([ 0.12226647, -0.71612595]),\n",
       " array([ 0.1197994 , -0.71587782]),\n",
       " array([ 0.11751816, -0.71564623]),\n",
       " array([ 0.11540905, -0.71543025]),\n",
       " array([ 0.11345934, -0.71522898]),\n",
       " array([ 0.11165719, -0.71504154]),\n",
       " array([ 0.10999162, -0.7148671 ]),\n",
       " array([ 0.10845242, -0.71470485]),\n",
       " array([ 0.10703012, -0.71455402]),\n",
       " array([ 0.10571596, -0.71441387]),\n",
       " array([ 0.1045018 , -0.71428371]),\n",
       " array([ 0.10338011, -0.71416288]),\n",
       " array([ 0.1023439 , -0.71405075]),\n",
       " array([ 0.10138672, -0.71394674]),\n",
       " array([ 0.10050258, -0.71385028]),\n",
       " array([ 0.09968594, -0.71376086]),\n",
       " array([ 0.09893169, -0.71367799]),\n",
       " array([ 0.09823508, -0.71360121]),\n",
       " array([ 0.09759174, -0.7135301 ]),\n",
       " array([ 0.0969976 , -0.71346424]),\n",
       " array([ 0.09644892, -0.71340326]),\n",
       " array([ 0.09594224, -0.71334682]),\n",
       " array([ 0.09547435, -0.71329458]),\n",
       " array([ 0.09504229, -0.71324624]),\n",
       " array([ 0.09464333, -0.71320152]),\n",
       " array([ 0.09427494, -0.71316015]),\n",
       " array([ 0.09393478, -0.71312189]),\n",
       " array([ 0.09362069, -0.7130865 ]),\n",
       " array([ 0.09333069, -0.71305378]),\n",
       " array([ 0.09306292, -0.71302353]),\n",
       " array([ 0.09281568, -0.71299557]),\n",
       " array([ 0.09258741, -0.71296972]),\n",
       " array([ 0.09237665, -0.71294582]),\n",
       " array([ 0.09218206, -0.71292374]),\n",
       " array([ 0.0920024 , -0.71290333]),\n",
       " array([ 0.09183652, -0.71288447]),\n",
       " array([ 0.09168338, -0.71286704]),\n",
       " array([ 0.09154198, -0.71285094]),\n",
       " array([ 0.09141144, -0.71283607]),\n",
       " array([ 0.09129092, -0.71282233]),\n",
       " array([ 0.09117965, -0.71280963]),\n",
       " array([ 0.09107693, -0.7127979 ]),\n",
       " array([ 0.09098209, -0.71278707]),\n",
       " array([ 0.09089453, -0.71277706]),\n",
       " array([ 0.09081369, -0.71276782]),\n",
       " array([ 0.09073907, -0.71275929]),\n",
       " array([ 0.09067017, -0.7127514 ]),\n",
       " array([ 0.09060656, -0.71274412]),\n",
       " array([ 0.09054784, -0.7127374 ]),\n",
       " array([ 0.09049362, -0.71273119]),\n",
       " array([ 0.09044357, -0.71272545]),\n",
       " array([ 0.09039737, -0.71272016]),\n",
       " array([ 0.09035471, -0.71271527]),\n",
       " array([ 0.09031533, -0.71271075]),\n",
       " array([ 0.09027897, -0.71270658]),\n",
       " array([ 0.09024541, -0.71270273]),\n",
       " array([ 0.09021442, -0.71269918]),\n",
       " array([ 0.09018581, -0.7126959 ]),\n",
       " array([ 0.0901594 , -0.71269287]),\n",
       " array([ 0.09013502, -0.71269007]),\n",
       " array([ 0.09011251, -0.71268748]),\n",
       " array([ 0.09009173, -0.7126851 ]),\n",
       " array([ 0.09007255, -0.71268289]),\n",
       " array([ 0.09005484, -0.71268086]),\n",
       " array([ 0.09003849, -0.71267898]),\n",
       " array([ 0.0900234 , -0.71267725]),\n",
       " array([ 0.09000947, -0.71267565]),\n",
       " array([ 0.0899966 , -0.71267417]),\n",
       " array([ 0.08998473, -0.71267281]),\n",
       " array([ 0.08997376, -0.71267155]),\n",
       " array([ 0.08996364, -0.71267038])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#x0 = np.array([-0.09406448078584173,0.7221310983970208])\n",
    "# x1,x2 values form bayesian optimization for 50 iterations\n",
    "x0 = np.array([0.23151603129184473,-0.7248785139747396])  \n",
    "x = np.array([0,0])\n",
    "obj = lambda x: ((4-(2.1*x[0]**2)+((x[0]**4)/3))*x[0]**2+(x[0]*x[1])+(-4+(4*x[1]**2))*x[1]**2)\n",
    "def grad(x):\n",
    "    return np.array([8*x[0]-2.1*4*x[0]**3+2*x[0]**5+x[1], x[0]-8*x[1]+16*x[1]**3])\n",
    "\n",
    "eps = 1e-3  # termination criterion\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps\n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "a = 0.01  # set a fixed step size to start with\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x, d):\n",
    "    a = 0.01  # initialize step size\n",
    "    \n",
    "    def phi(a,x,d):\n",
    "        return obj(x)+a*0.8*np.dot(grad(x),d)\n",
    "\n",
    "    while phi(a,x,d)<obj(x+a*d):  # while phi(a,x)<obj(x-a*grad(x)): # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "        \n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    d = -grad(x)\n",
    "    \n",
    "    a = line_search(x, d)\n",
    "    \n",
    "    x = x+a*d\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "    print(grad(x))\n",
    "soln  # print the search trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23886786",
   "metadata": {},
   "source": [
    "#### Gradiant Descent method with inital values from Bayesian optimization, iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d0097cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.02312783  0.12812248]\n",
      "[-0.02260984  0.10672699]\n",
      "[-0.02191794  0.08902438]\n",
      "[-0.02110263  0.07434874]\n",
      "[-0.02020379  0.06216218]\n",
      "[-0.01925284  0.05202792]\n",
      "[-0.0182744   0.04358969]\n",
      "[-0.01728757  0.03655578]\n",
      "[-0.0163071   0.03068659]\n",
      "[-0.01534414  0.02578475]\n",
      "[-0.01440704  0.02168733]\n",
      "[-0.01350185  0.01825957]\n",
      "[-0.01263279  0.0153898 ]\n",
      "[-0.01180265  0.01298536]\n",
      "[-0.01101306  0.01096928]\n",
      "[-0.01026477  0.00927754]\n",
      "[-0.0095578   0.00785685]\n",
      "[-0.00889167  0.00666283]\n",
      "[-0.00826545  0.00565846]\n",
      "[-0.00767796  0.00481287]\n",
      "[-0.00712777  0.00410029]\n",
      "[-0.0066133   0.00349921]\n",
      "[-0.00613289  0.00299164]\n",
      "[-0.00568482  0.00256254]\n",
      "[-0.00526738  0.00219936]\n",
      "[-0.00487882  0.00189157]\n",
      "[-0.00451746  0.00163036]\n",
      "[-0.00418164  0.00140837]\n",
      "[-0.00386977  0.00121941]\n",
      "[-0.00358032  0.00105831]\n",
      "[-0.00331181  0.00092072]\n",
      "[-0.00306285  0.00080299]\n",
      "[-0.00283211  0.00070206]\n",
      "[-0.00261835  0.00061537]\n",
      "[-0.00242039  0.00054074]\n",
      "[-0.0022371   0.00047637]\n",
      "[-0.00206746  0.0004207 ]\n",
      "[-0.00191049  0.00037246]\n",
      "[-0.00176527  0.00033055]\n",
      "[-0.00163095  0.00029406]\n",
      "[-0.00150674  0.0002622 ]\n",
      "[-0.00139189  0.00023432]\n",
      "[-0.00128571  0.00020986]\n",
      "[-0.00118757  0.00018834]\n",
      "[-0.00109686  0.00016937]\n",
      "[-0.00101304  0.00015259]\n",
      "[-0.00093558  0.00013773]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([-0.09406448,  0.7221311 ]),\n",
       " array([-0.0938304 ,  0.72059069]),\n",
       " array([-0.09359912,  0.71930947]),\n",
       " array([-0.09337302,  0.7182422 ]),\n",
       " array([-0.09315384,  0.71735196]),\n",
       " array([-0.09294282,  0.71660847]),\n",
       " array([-0.09274078,  0.71598685]),\n",
       " array([-0.09254825,  0.71546657]),\n",
       " array([-0.09236551,  0.71503067]),\n",
       " array([-0.09219263,  0.71466511]),\n",
       " array([-0.09202956,  0.71435825]),\n",
       " array([-0.09187612,  0.7141004 ]),\n",
       " array([-0.09173205,  0.71388353]),\n",
       " array([-0.09159703,  0.71370093]),\n",
       " array([-0.0914707 ,  0.71354703]),\n",
       " array([-0.09135267,  0.71341718]),\n",
       " array([-0.09124254,  0.71330749]),\n",
       " array([-0.0911399 ,  0.71321471]),\n",
       " array([-0.09104432,  0.71313614]),\n",
       " array([-0.0909554 ,  0.71306951]),\n",
       " array([-0.09087275,  0.71301293]),\n",
       " array([-0.09079597,  0.7129648 ]),\n",
       " array([-0.09072469,  0.7129238 ]),\n",
       " array([-0.09065856,  0.71288881]),\n",
       " array([-0.09059723,  0.71285889]),\n",
       " array([-0.09054038,  0.71283326]),\n",
       " array([-0.09048771,  0.71281127]),\n",
       " array([-0.09043892,  0.71279235]),\n",
       " array([-0.09039374,  0.71277605]),\n",
       " array([-0.09035193,  0.71276197]),\n",
       " array([-0.09031323,  0.71274977]),\n",
       " array([-0.09027743,  0.71273919]),\n",
       " array([-0.09024431,  0.71272998]),\n",
       " array([-0.09021368,  0.71272195]),\n",
       " array([-0.09018536,  0.71271493]),\n",
       " array([-0.09015917,  0.71270878]),\n",
       " array([-0.09013497,  0.71270337]),\n",
       " array([-0.0901126 ,  0.71269861]),\n",
       " array([-0.09009193,  0.7126944 ]),\n",
       " array([-0.09007282,  0.71269068]),\n",
       " array([-0.09005517,  0.71268737]),\n",
       " array([-0.09003886,  0.71268443]),\n",
       " array([-0.09002379,  0.71268181]),\n",
       " array([-0.09000987,  0.71267946]),\n",
       " array([-0.08999701,  0.71267737]),\n",
       " array([-0.08998514,  0.71267548]),\n",
       " array([-0.08997417,  0.71267379]),\n",
       " array([-0.08996404,  0.71267226])]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x1,x2 values form bayesian optimization for 100 iterations\n",
    "x0 = np.array([-0.09406448078584173,0.7221310983970208])\n",
    "#x0 = np.array([0.23151603129184473,-0.7248785139747396])  \n",
    "x = np.array([0,0])\n",
    "obj = lambda x: ((4-(2.1*x[0]**2)+((x[0]**4)/3))*x[0]**2+(x[0]*x[1])+(-4+(4*x[1]**2))*x[1]**2)\n",
    "def grad(x):\n",
    "    return np.array([8*x[0]-2.1*4*x[0]**3+2*x[0]**5+x[1], x[0]-8*x[1]+16*x[1]**3])\n",
    "\n",
    "eps = 1e-3  # termination criterion\n",
    "k = 0  # counter\n",
    "soln = [x0]  # use an array to store the search steps\n",
    "x = soln[k]  # start with the initial guess\n",
    "error = np.linalg.norm(grad(x))  # compute the error. Note you will need to compute the norm for 2D grads, rather than the absolute value\n",
    "a = 0.01  # set a fixed step size to start with\n",
    "\n",
    "# Armijo line search\n",
    "def line_search(x, d):\n",
    "    a = 0.01  # initialize step size\n",
    "    \n",
    "    def phi(a,x,d):\n",
    "        return obj(x)+a*0.8*np.dot(grad(x),d)\n",
    "\n",
    "    while phi(a,x,d)<obj(x+a*d):  # while phi(a,x)<obj(x-a*grad(x)): # if f(x+a*d)>phi(a) then backtrack. d is the search direction\n",
    "        a = 0.5*a\n",
    "        \n",
    "    return a\n",
    "\n",
    "while error >= eps:  # keep searching while gradient norm is larger than eps\n",
    "    d = -grad(x)\n",
    "    \n",
    "    a = line_search(x, d)\n",
    "    \n",
    "    x = x+a*d\n",
    "    soln.append(x)\n",
    "    error = np.linalg.norm(grad(x))\n",
    "    print(grad(x))\n",
    "soln  # print the search trajectory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03e64fa1",
   "metadata": {},
   "source": [
    "While using __Bayesian optimization__, the values for x1 and x2 are changing with respect to number of iterations.\n",
    "For __50__ iterations, the values are__\n",
    "'x1': 0.23151603129184473, 'x2': -0.7248785139747396\n",
    "For __100__ iterations:\n",
    "-0.09406448078584173, 'x2': 0.7221310983970208\n",
    "While using __Gradient descent__ the stationary point with initial condition as (0,0), is [0,0].\n",
    "When I have taken the x1,x2 values which I got from Bayesian optimization as initial conditions in gradient descent algorithm, I got gradient as close to 0 and the values of x1,x2 obtained are also close to the values obtained in bayesian optimization for 100 iterations.\n",
    "\n",
    "|Gradient descent                  | |Bayesian Optimization                               | \n",
    "|array([-0.08996404,  0.71267226])]| |-0.09406448078584173, 'x2': 0.7221310983970208      |\n",
    "|array([ 0.08996364, -0.71267038])]| |'x1': 0.23151603129184473, 'x2': -0.7248785139747396|\n",
    "\n",
    "So, it can be inferred that with more number of iterations performed in Bayesian optimizations, the close we get to the optimum value."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
